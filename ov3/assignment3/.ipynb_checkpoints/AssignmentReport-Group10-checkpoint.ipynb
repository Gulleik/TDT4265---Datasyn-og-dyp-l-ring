{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an outline for your report to ease the amount of work required to create your report. Jupyter notebook supports markdown, and I recommend you to check out this [cheat sheet](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet). If you are not familiar with markdown.\n",
    "\n",
    "Before delivery, **remember to convert this file to PDF**. You can do it in two ways:\n",
    "1. Print the webpage (ctrl+P or cmd+P)\n",
    "2. Export with latex. This is somewhat more difficult, but you'll get somehwat of a \"prettier\" PDF. Go to File -> Download as -> PDF via LaTeX. You might have to install nbconvert and pandoc through conda; `conda install nbconvert pandoc`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1a)\n",
    "\n",
    "![](datasyn1a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## task 1b)\n",
    "\n",
    "The max Polling layer is the layer responsible for reducing the sensitivity to translationial variations\n",
    "in the input\n",
    "\n",
    "## task 1c)\n",
    "\n",
    "you should use a padding of 2 on each side\n",
    "\n",
    "## task 1d)\n",
    "\n",
    "The image dimentions is reduced from from 512 to 504. when no padding is used the dimentions of the kernel equals number of lost pixels + 1 which is 9.\n",
    "The kernel is 9x9.\n",
    "## task 1e)\n",
    "\n",
    "With the given spesifications the spatial dimensions of the pooled feature maps in the first pooling is 252x252\n",
    "## task 1f)\n",
    "\n",
    "since there is no padding and the kernel size is 3 the image will be reduced by 2 pixels in each dimention. this results in the size of the feature maps in the second layer being 250x250.\n",
    "## task 1g)\n",
    "\n",
    "number of parameters in the first layer: (5*5*3 + 1)* 32 = 2432,\n",
    "number of parameters in the second layer: (5*5*32 + 1)* 64 = 51264,\n",
    "number of parameters in the third layer: (5*5*3 + 1)* 32 = 204928,\n",
    "number of parameters in the forth layer: (5*5*3 + 1)* 32 = 131136,\n",
    "number of parameters in the fift layer: (5*5*3 + 1)* 32 = 650,\n",
    "total number of parameters: 390410\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2a)\n",
    "![](plots/task2_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2b)\n",
    "\n",
    "The final accuracy values: \n",
    "Train accuracy: 0.8770,\n",
    "Validation accuracy: 0.7296,\n",
    "Test accuracy: 0.7295"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3a)\n",
    "Our first CNN had the following architecture:\n",
    "![](gulleikCNN.png)\n",
    "The first convolutional layer has a filter size of 5×5 with a padding of 2, while the second and third one has a filter size of 3x3 with a padding of 1. All convolutional layers had a stride of 1. The\n",
    "flatten layer takes an image with shape (Height) × (Width) × (Number of Feature Maps), and flattens\n",
    "it to a single vector with size (Height) · (Width) · (Number of Feature Maps)  Each MaxPool2D layer has a stride of 2 and a kernel size of 2 × 2. In addition to changing the filter size and the number of hidden units was regularization added in form of weight_decay in the optimizer. The level of weight decay was set to 1e-7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3b)\n",
    "![](task3b.png)\n",
    "![](plots/task3f_plot.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 3c)\n",
    "### Task 3d)\n",
    "### Task 3e)\n",
    "### Task 3f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4a)\n",
    "Briefly report your hyperparameters, including\n",
    "optimizer, batch size, learning rate and potential data augmentation used\n",
    "\n",
    "Here you can see the results from our Resnet18. For this resnet Adam was used as an optimizer, the batch size was 32, the learning rate was 5e-4, the early stop count was 4, and the weight decay was set to 0. \n",
    "While preprocessing the images, we resized them to 224x224 pixels, and we changed the mean and std to mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] for the preprocessing\n",
    "\n",
    "![](plots/task4a_plot.png)\n",
    "\n",
    "Our final test accuracy was 0.8923 or 89.23%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4b)\n",
    "<img src=\"images/weights14.png\" alt=\"Drawing\" style=\"width: 200px;\"/><img src=\"images/weights26.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/weights32.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/weights49.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/weights52.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "<img src=\"images/activations14.png\" alt=\"Drawing\" style=\"width: 200px;\"/><img src=\"images/activations26.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations32.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations49.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations52.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Here we can see the different visualizations of the activations from the first convolutional layer from the fliter at index 14, 26, 32, 49, and 52.\n",
    "From what we can see is the CNN able to detect the outline of the zebra as well as its stripy pattern. Some  of the filters are also clearly able to seperate the sky form the ground in the background, while in others the background sort of blends in with the zebra. While the activations make sense in some way its significantly more to understand what the filters visualizations mean."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4c)\n",
    "<img src=\"images/activations4c0.png\" alt=\"Drawing\" style=\"width: 200px;\"/><img src=\"images/activations4c1.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c2.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c3.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c4.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "<img src=\"images/activations4c5.png\" alt=\"Drawing\" style=\"width: 200px;\"/> <img src=\"images/activations4c6.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c7.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c8.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "<img src=\"images/activations4c9.png\" alt=\"Drawing\" style=\"width: 200px;\"/>\n",
    "\n",
    "Here we can see the filter activations from running the image throu the first 10 filters of the network. We can see the the orignial image have been reduced by the polling layers to such an extent that the zebra is no longer reconizable. The filters do however return a set fo different images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
