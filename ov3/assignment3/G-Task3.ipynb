{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "korean-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import matplotlib.pyplot as plt\n",
    "import utils\n",
    "from torch import nn\n",
    "from dataloaders import load_cifar10\n",
    "from trainer import Trainer, compute_loss_and_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "collect-cliff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExampleModel(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_channels,\n",
    "                 num_classes):\n",
    "        \"\"\"\n",
    "            Is called when model is initialized.\n",
    "            Args:\n",
    "                image_channels. Number of color channels in image (3)\n",
    "                num_classes: Number of classes we want to predict (10)\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        num_filters = 32  # Set number of filters in first conv layer\n",
    "        self.num_classes = num_classes\n",
    "        # Define the convolutional layers\n",
    "        self.feature_extractor = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.Conv2d(64, 128, 5, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "        )\n",
    "        # The output of feature_extractor will be [batch_size, num_filters, 16, 16]\n",
    "        self.num_output_features = 32*32*32\n",
    "\n",
    "\n",
    "        # Initialize our last fully connected layer\n",
    "        # Inputs all extracted features from the convolutional layers\n",
    "        # Outputs num_classes predictions, 1 for each class.\n",
    "        # There is no need for softmax activation function, as this is\n",
    "        # included with nn.CrossEntropyLoss\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass through the model\n",
    "        Args:\n",
    "            x: Input image, shape: [batch_size, 3, 32, 32]\n",
    "        \"\"\"\n",
    "        # TODO: Implement this function (Task  2a)\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.feature_extractor(x)\n",
    "        x = x.view(batch_size,-1)\n",
    "        out = self.classifier(x)\n",
    "        expected_shape = (batch_size, self.num_classes)\n",
    "        assert out.shape == (batch_size, self.num_classes),\\\n",
    "            f\"Expected output of forward pass to be: {expected_shape}, but got: {out.shape}\"\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bright-contest",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_plots(trainer: Trainer, name: str):\n",
    "    plot_path = pathlib.Path(\"plots\")\n",
    "    plot_path.mkdir(exist_ok=True)\n",
    "    # Save plots and show them\n",
    "    plt.figure(figsize=(20, 8))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.title(\"Cross Entropy Loss\")\n",
    "    utils.plot_loss(trainer.train_history[\"loss\"], label=\"Training loss\", npoints_to_average=10)\n",
    "    utils.plot_loss(trainer.validation_history[\"loss\"], label=\"Validation loss\")\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.title(\"Accuracy\")\n",
    "    utils.plot_loss(trainer.validation_history[\"accuracy\"], label=\"Validation Accuracy\")\n",
    "    plt.legend()\n",
    "    plt.savefig(plot_path.joinpath(f\"{name}_plot.png\"))\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "regulation-waterproof",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "ExampleModel(\n",
      "  (feature_extractor): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "    (7): ReLU()\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=64, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=64, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch: 0, Batches per seconds: 44.84, Global step:    351, Validation Loss: 1.69, Validation Accuracy: 0.379\n",
      "Epoch: 0, Batches per seconds: 54.93, Global step:    702, Validation Loss: 1.38, Validation Accuracy: 0.499\n",
      "Epoch: 1, Batches per seconds: 51.12, Global step:   1053, Validation Loss: 1.34, Validation Accuracy: 0.500\n",
      "Epoch: 1, Batches per seconds: 54.81, Global step:   1404, Validation Loss: 1.20, Validation Accuracy: 0.575\n",
      "Epoch: 2, Batches per seconds: 52.63, Global step:   1755, Validation Loss: 1.09, Validation Accuracy: 0.612\n",
      "Epoch: 2, Batches per seconds: 54.98, Global step:   2106, Validation Loss: 1.00, Validation Accuracy: 0.657\n",
      "Epoch: 3, Batches per seconds: 53.25, Global step:   2457, Validation Loss: 0.91, Validation Accuracy: 0.686\n",
      "Epoch: 3, Batches per seconds: 54.94, Global step:   2808, Validation Loss: 1.05, Validation Accuracy: 0.625\n",
      "Epoch: 4, Batches per seconds: 53.66, Global step:   3159, Validation Loss: 0.92, Validation Accuracy: 0.686\n",
      "Epoch: 4, Batches per seconds: 55.00, Global step:   3510, Validation Loss: 0.81, Validation Accuracy: 0.713\n",
      "Epoch: 5, Batches per seconds: 53.87, Global step:   3861, Validation Loss: 0.81, Validation Accuracy: 0.724\n",
      "Epoch: 5, Batches per seconds: 54.84, Global step:   4212, Validation Loss: 0.81, Validation Accuracy: 0.714\n",
      "Epoch: 6, Batches per seconds: 53.55, Global step:   4563, Validation Loss: 0.77, Validation Accuracy: 0.737\n",
      "Epoch: 6, Batches per seconds: 54.29, Global step:   4914, Validation Loss: 0.80, Validation Accuracy: 0.744\n",
      "Epoch: 7, Batches per seconds: 53.36, Global step:   5265, Validation Loss: 0.79, Validation Accuracy: 0.734\n",
      "Epoch: 7, Batches per seconds: 54.18, Global step:   5616, Validation Loss: 0.89, Validation Accuracy: 0.730\n",
      "Early stop criteria met\n",
      "Early stopping.\n",
      "OrderedDict([(351, tensor(0.3792, device='cuda:0')), (702, tensor(0.4990, device='cuda:0')), (1053, tensor(0.5004, device='cuda:0')), (1404, tensor(0.5746, device='cuda:0')), (1755, tensor(0.6118, device='cuda:0')), (2106, tensor(0.6568, device='cuda:0')), (2457, tensor(0.6860, device='cuda:0')), (2808, tensor(0.6252, device='cuda:0')), (3159, tensor(0.6864, device='cuda:0')), (3510, tensor(0.7126, device='cuda:0')), (3861, tensor(0.7238, device='cuda:0')), (4212, tensor(0.7138, device='cuda:0')), (4563, tensor(0.7366, device='cuda:0')), (4914, tensor(0.7442, device='cuda:0')), (5265, tensor(0.7344, device='cuda:0')), (5616, tensor(0.7296, device='cuda:0'))])\n",
      "OrderedDict()\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Trainer' object has no attribute 'test_history'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-315633a1518f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalidation_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_history\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'Trainer' object has no attribute 'test_history'"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Set the random generator seed (parameters, shuffling etc).\n",
    "    # You can try to change this and check if you still get the same result! \n",
    "    utils.set_seed(0)\n",
    "    epochs = 10\n",
    "    batch_size = 64\n",
    "    learning_rate = 5e-2\n",
    "    early_stop_count = 4\n",
    "    dataloaders = load_cifar10(batch_size)\n",
    "    model = ExampleModel(image_channels=3, num_classes=10)\n",
    "    trainer = Trainer(\n",
    "        batch_size,\n",
    "        learning_rate,\n",
    "        early_stop_count,\n",
    "        epochs,\n",
    "        model,\n",
    "        dataloaders\n",
    "    )\n",
    "    trainer.train()\n",
    "    \n",
    "    dataloader_train, dataloader_val, dataloader_test = dataloaders\n",
    "    print(compute_loss_and_accuracy(dataloader_train, model, torch.nn.CrossEntropyLoss()))\n",
    "    print(compute_loss_and_accuracy(dataloader_val, model, torch.nn.CrossEntropyLoss()))\n",
    "    print(compute_loss_and_accuracy(dataloader_test, model, torch.nn.CrossEntropyLoss()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "embedded-congo",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
