{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "amended-german",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from task2a import one_hot_encode, pre_process_images, SoftmaxModel, gradient_approximation_test\n",
    "from task2 import SoftmaxTrainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "handmade-divorce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: X: (20000, 784), Y: (20000, 1)\n",
      "Validation shape: X: (10000, 784), Y: (10000, 1)\n",
      "Initializing weight to shape: (785, 64)\n",
      "Initializing weight to shape: (64, 64)\n",
      "Initializing weight to shape: (64, 10)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Simple test on one-hot encoding\n",
    "    Y = np.zeros((1, 1), dtype=int)\n",
    "    Y[0, 0] = 3\n",
    "    Y = one_hot_encode(Y, 10)\n",
    "    assert Y[0, 3] == 1 and Y.sum() == 1, \\\n",
    "        f\"Expected the vector to be [0,0,0,1,0,0,0,0,0,0], but got {Y}\"\n",
    "\n",
    "    X_train, Y_train, *_ = utils.load_full_mnist()\n",
    "    X_train = pre_process_images(X_train)\n",
    "    Y_train = one_hot_encode(Y_train, 10)\n",
    "    assert X_train.shape[1] == 785,\\\n",
    "        f\"Expected X_train to have 785 elements per image. Shape was: {X_train.shape}\"\n",
    "\n",
    "    # Modify your network here\n",
    "    neurons_per_layer = [64, 64, 10]\n",
    "    use_improved_sigmoid = True\n",
    "    use_improved_weight_init = True\n",
    "    model = SoftmaxModel(\n",
    "        neurons_per_layer, use_improved_sigmoid, use_improved_weight_init)\n",
    "\n",
    "    # Gradient approximation check for 100 images\n",
    "    X_train = X_train[:100]\n",
    "    Y_train = Y_train[:100]\n",
    "    for layer_idx, w in enumerate(model.ws):\n",
    "        model.ws[layer_idx] = np.random.uniform(-1, 1, size=w.shape)\n",
    "\n",
    "    gradient_approximation_test(model, X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "royal-november",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
